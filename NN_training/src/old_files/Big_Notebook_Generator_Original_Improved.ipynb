{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import atmos_physics as atmos_physics\n",
    "import math\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(training_split, longitudes, times):\n",
    "    pure_split = int(longitudes*times*training_split)\n",
    "    return math.floor(float(pure_split) / longitudes) * longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath = \"/ocean/projects/ees220005p/gmooers/GM_Data/**00000[1]**.nc4\"\n",
    "filepath = \"/ocean/projects/ees220005p/gmooers/GM_Data/**0000012[26]**.nc4\"\n",
    "savepath = \"/ocean/projects/ees220005p/gmooers/GM_Data/training_data/\"\n",
    "n_z_input = 49\n",
    "train_size=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = xr.open_mfdataset(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = variables.lon  # m\n",
    "y = variables.lat  # m\n",
    "z = variables.z  # m\n",
    "p = variables.p  # hPa\n",
    "rho = variables.rho  # kg/m^3\n",
    "terra = variables.TERRA[:,:n_z_input]\n",
    "SFC_PRES = variables.SFC_REFERENCE_P\n",
    "SKT = variables.SKT\n",
    "n_x = x.size\n",
    "n_y = y.size\n",
    "n_z = z.size\n",
    "n_files = terra.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_lat = np.zeros((n_files, n_y, n_x))\n",
    "sin_lon = np.zeros((n_files, n_y, n_x))\n",
    "cos_lat[:, :, :] = xr.ufuncs.cos(xr.ufuncs.radians(y.values[None, :, None]))\n",
    "sin_lon[:, :, :] = xr.ufuncs.sin(xr.ufuncs.radians(x.values[None, None, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adz = xr.zeros_like(z[:n_z_input]) \n",
    "dz = 0.5*(z[0]+z[1]) \n",
    "adz[0] = 1.\n",
    "\n",
    "for k in range(1,n_z_input-1): # range doesn't include stopping number\n",
    "    adz[k] = 0.5*(z[k+1]-z[k-1])/dz\n",
    "\n",
    "adz[n_z_input-1] = (z[n_z_input-1]-z[n_z_input-2])/dz\n",
    "rho_dz = adz*dz*rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tin = variables.TABS_SIGMA[:,:n_z_input] #originally just called tabs\n",
    "Qrad = variables.QRAD_SIGMA[:,:n_z_input] / 86400\n",
    "qt = (variables.QV_SIGMA[:,:n_z_input] + variables.QC_SIGMA[:,:n_z_input] + variables.QI_SIGMA[:,:n_z_input]) / 1000.0 # originally called qt\n",
    "qp = variables.QP_SIGMA[:,:n_z_input] / 1000.0\n",
    "q_auto_out = -1.0*variables.QP_MICRO_SIGMA[:,:n_z_input] / 1000.0\n",
    "qpflux_z_coarse = variables.RHOQPW_SIGMA[:,:n_z_input] / 1000.0\n",
    "T_adv_out = variables.T_FLUX_Z_OUT_SUBGRID_SIGMA[:,:n_z_input]     #originally tflux_z\n",
    "q_adv_out = variables.Q_FLUX_Z_OUT_SUBGRID_SIGMA[:,:n_z_input] / 1000.0 #originally qtflux_z\n",
    "qpflux_z = variables.QP_FLUX_Z_OUT_SUBGRID_SIGMA[:,:n_z_input] / 1000.0 \n",
    "w = variables.W[:,:n_z_input]  # m/s\n",
    "precip = variables.PREC_SIGMA[:,:n_z_input]  # precipitation flux kg/m^2/s\n",
    "cloud_qt_flux = variables.SED_SIGMA[:,:n_z_input] / 1000.0\n",
    "cloud_lat_heat_flux = variables.LSED_SIGMA[:,:n_z_input] \n",
    "qpflux_diff_coarse_z = variables.RHOQPS_SIGMA[:,:n_z_input] / 1000.0  # SGS qp flux kg/m^2/s Note that I need this variable\n",
    "#q_auto_out = - dqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pr = 1.0 / (atmos_physics.tprmax - atmos_physics.tprmin)\n",
    "omp = np.maximum(0.0, np.minimum(1.0, (Tin - atmos_physics.tprmin) * a_pr))\n",
    "fac = (atmos_physics.L + atmos_physics.Lf * (1.0 - omp)) / atmos_physics.cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_sed_fluxc_out = ((atmos_physics.L + atmos_physics.Lf) * cloud_qt_flux + cloud_lat_heat_flux) / atmos_physics.Lf\n",
    "q_sed_fluxi_out = - (atmos_physics.L * cloud_qt_flux + cloud_lat_heat_flux) / atmos_physics.Lf\n",
    "q_sed_flux_tot  = cloud_qt_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfac_dz = np.zeros((n_files, n_z_input, n_y, n_x))\n",
    "for k in range(n_z_input - 1):\n",
    "    kb = max(0, k - 1)\n",
    "    dfac_dz[:, k, :, :] = (fac[:, k + 1, :, :] - fac[:, k, :, :]) / rho_dz[k, :] * rho[:, k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tout = dfac_dz * (qpflux_z_coarse + qpflux_diff_coarse_z - precip) / rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = get_train_test_split(train_size, n_x, n_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict_train = {}\n",
    "my_dict_test = {}\n",
    "my_weight_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chunks = {'time':100, 'z': 49, 'lat': 100, 'lon': 100}\n",
    "Tin =  da.from_array(Tin, chunks=new_chunks)\n",
    "Tin = Tin.reshape(n_z_input, n_y, n_files * n_x)\n",
    "my_dict_train[\"Tin\"] = ((\"z\",\"lat\",\"sample\"), Tin[...,:split_index])\n",
    "my_dict_test[\"Tin\"] = ((\"z\",\"lat\",\"sample\"), Tin[...,split_index:])\n",
    "\n",
    "qin = da.from_array(qt, chunks=new_chunks) \n",
    "qin = qin.reshape(n_z_input, n_y, n_files * n_x) \n",
    "my_dict_train[\"qin\"] = ((\"z\",\"lat\",\"sample\"), qin[...,:split_index])\n",
    "my_dict_test[\"qin\"] = ((\"z\",\"lat\",\"sample\"), qin[...,split_index:])\n",
    "    \n",
    "\n",
    "Tout = da.from_array(Tout, chunks=new_chunks)  \n",
    "Tout = Tout.reshape(n_z_input, n_y, n_files * n_x)\n",
    "my_dict_train[\"Tout\"] = ((\"z\",\"lat\",\"sample\"), Tout[...,:split_index])\n",
    "my_dict_test[\"Tout\"] = ((\"z\",\"lat\",\"sample\"), Tout[...,split_index:])\n",
    "\n",
    "T_adv_out = da.from_array(T_adv_out, chunks=new_chunks)  \n",
    "T_adv_out = T_adv_out.reshape(n_z_input, n_y, n_files * n_x) \n",
    "my_dict_train[\"T_adv_out\"] = ((\"z\",\"lat\",\"sample\"), T_adv_out[...,:split_index])\n",
    "my_dict_test[\"T_adv_out\"] = ((\"z\",\"lat\",\"sample\"), T_adv_out[...,split_index:])\n",
    "        \n",
    "q_adv_out = da.from_array(q_adv_out, chunks=new_chunks)  \n",
    "q_adv_out = q_adv_out.reshape(n_z_input, n_y, n_files * n_x) \n",
    "my_dict_train[\"q_adv_out\"] = ((\"z\",\"lat\",\"sample\"), q_adv_out[...,:split_index])\n",
    "my_dict_test[\"q_adv_out\"] = ((\"z\",\"lat\",\"sample\"), q_adv_out[...,split_index:])\n",
    "        \n",
    "q_auto_out = da.from_array(q_auto_out, chunks=new_chunks) \n",
    "q_auto_out = q_auto_out.reshape(n_z_input, n_y, n_files * n_x) \n",
    "my_dict_train[\"q_auto_out\"] = ((\"z\",\"lat\",\"sample\"), q_auto_out[...,:split_index])\n",
    "my_dict_test[\"q_auto_out\"] = ((\"z\",\"lat\",\"sample\"), q_auto_out[...,split_index:])\n",
    "\n",
    "q_sed_flux_tot = da.from_array(q_sed_flux_tot, chunks=new_chunks)\n",
    "q_sed_flux_tot = q_sed_flux_tot.reshape(n_z_input, n_y, n_files * n_x) \n",
    "my_dict_train[\"q_sed_flux_tot\"] = ((\"z\",\"lat\",\"sample\"), q_sed_flux_tot[...,:split_index])\n",
    "my_dict_test[\"q_sed_flux_tot\"] = ((\"z\",\"lat\",\"sample\"), q_sed_flux_tot[...,split_index:])\n",
    "    \n",
    "\n",
    "terra = da.from_array(terra, chunks=new_chunks) \n",
    "terra = terra.reshape(n_z_input, n_y, n_files * n_x)\n",
    "my_dict_train[\"terra\"] = ((\"z\",\"lat\",\"sample\"), terra[...,:split_index])\n",
    "my_dict_test[\"terra\"] = ((\"z\",\"lat\",\"sample\"), terra[...,split_index:])\n",
    "    \n",
    "small_chunks = {'time':100, 'lat': 100, 'lon': 100}\n",
    "sfc_pres = da.from_array(SFC_PRES, chunks=small_chunks)\n",
    "sfc_pres = sfc_pres.reshape(n_y, n_files * n_x) \n",
    "my_dict_train[\"sfc_pres\"] = ((\"lat\",\"sample\"), sfc_pres[...,:split_index])\n",
    "my_dict_test[\"sfc_pres\"] = ((\"lat\",\"sample\"), sfc_pres[...,split_index:])\n",
    "    \n",
    "skt = da.from_array(SKT, chunks=small_chunks) \n",
    "skt = skt.reshape(n_y, n_files * n_x)\n",
    "my_dict_train[\"skt\"] = ((\"lat\",\"sample\"), skt[...,:split_index])\n",
    "my_dict_test[\"skt\"] = ((\"lat\",\"sample\"), skt[...,split_index:])\n",
    "    \n",
    "cos_lat = np.expand_dims(cos_lat, axis=0)\n",
    "cos_lat = np.moveaxis(cos_lat, 2, 3)\n",
    "cos_lat = np.reshape(cos_lat, (1, n_y, -1)).squeeze()\n",
    "my_dict_train[\"cos_lat\"] = ((\"lat\",\"sample\"), cos_lat[...,:split_index])\n",
    "my_dict_test[\"cos_lat\"] = ((\"lat\",\"sample\"), cos_lat[...,split_index:])\n",
    "\n",
    "sin_lon = np.expand_dims(sin_lon, axis=0)\n",
    "sin_lon = np.moveaxis(sin_lon, 2, 3)\n",
    "sin_lon = np.reshape(sin_lon, (1, n_y, -1)).squeeze()\n",
    "my_dict_train[\"sin_lon\"] = ((\"lat\",\"sample\"), sin_lon[...,:split_index])\n",
    "my_dict_test[\"sin_lon\"] = ((\"lat\",\"sample\"), sin_lon[...,split_index:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_renormalization_factors(Tout, tflux_z, qtflux_z, qmic, qsed, rho_dz):\n",
    "    '''Renormalize outputs assuming flux form renormalization for T_rad+rest, Tadv, qadv, qmic, qsed.'''\n",
    "\n",
    "    # Calculate the differences along the vertical axis (assumed to be the first dimension here)\n",
    "    zTout = -(da.diff(tflux_z, axis=0) / rho_dz[:, None, None])\n",
    "    zqout = -(da.diff(qtflux_z, axis=0) / rho_dz[:, None, None])\n",
    "    zqsed = -(da.diff(qsed, axis=0) / rho_dz[:, None, None])\n",
    "\n",
    "    # Handle the top boundary condition where the flux is defined to be zero at the top half-level\n",
    "    zTout = da.concatenate([zTout, -tflux_z[-1, :, :][None, :, :] / rho_dz[-1]], axis=0)\n",
    "    zqout = da.concatenate([zqout, -qtflux_z[-1, :, :][None, :, :] / rho_dz[-1]], axis=0)\n",
    "    zqsed = da.concatenate([zqsed, -qsed[-1, :, :][None, :, :] / rho_dz[-1]], axis=0)\n",
    "\n",
    "    # Rescale humidity tendencies\n",
    "    L_cp_ratio = atmos_physics.L / atmos_physics.cp\n",
    "    zqsed = zqsed * L_cp_ratio\n",
    "    qmic = qmic * L_cp_ratio\n",
    "    zqout = zqout * L_cp_ratio\n",
    "\n",
    "    # Compute standard deviations\n",
    "    std1 = da.std(Tout, axis=(1, 2))\n",
    "    std2 = da.std(zTout, axis=(1, 2))\n",
    "    std3 = da.std(zqout, axis=(1, 2))\n",
    "    std4 = da.std(qmic, axis=(1, 2))\n",
    "    std5 = da.std(zqsed, axis=(1, 2))\n",
    "\n",
    "    # Normalize the standard deviations\n",
    "    std_min = da.min([std1, std2, std3, std4, std5])\n",
    "    std_factors = da.array([std1, std2, std3, std4, std5]) / std_min\n",
    "\n",
    "    return std_factors.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array<reshape, shape=(49, 426, 1536), dtype=float32, chunksize=(49, 426, 1536)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_adv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (z: 49)>\n",
       "dask.array<shape=(49,), dtype=float64, chunksize=(49,)>\n",
       "Coordinates:\n",
       "  * z        (z) float64 20.0 61.2 104.9 151.2 ... 1.247e+04 1.297e+04 1.347e+04\n",
       "    time     float64 21.42"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho_dz[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-440ae5bf1ddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                           \u001b[0mq_auto_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                           \u001b[0mq_sed_flux_tot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                           rho_dz[:,0]) \n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-72b528be9653>\u001b[0m in \u001b[0;36mcalculate_renormalization_factors\u001b[0;34m(Tout, tflux_z, qtflux_z, qmic, qsed, rho_dz)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Calculate the differences along the vertical axis (assumed to be the first dimension here)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mzTout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflux_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrho_dz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mzqout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqtflux_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrho_dz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mzqsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqsed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrho_dz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CPU/lib/python3.7/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# xarray-style array indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_key_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CPU/lib/python3.7/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m_item_key_to_dict\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanded_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CPU/lib/python3.7/site-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36mexpanded_indexer\u001b[0;34m(key, ndim)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mnew_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'too many indices'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mnew_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices"
     ]
    }
   ],
   "source": [
    "norm_list = calculate_renormalization_factors(Tout[...,:split_index],\n",
    "                                                          T_adv_out[...,:split_index],\n",
    "                                                          q_adv_out[...,:split_index],\n",
    "                                                          q_auto_out[...,:split_index],\n",
    "                                                          q_sed_flux_tot[...,split_index:],\n",
    "                                                          rho_dz[:,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_weight_dict['norms'] = ((\"norm\"), norm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = xr.Dataset(\n",
    "    my_dict_train,\n",
    "    coords={\n",
    "        \"z\": z[:n_z_input].values,\n",
    "        \"lat\": y.values,\n",
    "        \"sample\": np.arange(0,n_files*len(x.values), 1)[:split_index],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = xr.Dataset(\n",
    "    my_dict_test,\n",
    "    coords={\n",
    "        \"z\": z[:n_z_input].values,\n",
    "        \"lat\": y.values,\n",
    "        \"sample\": np.arange(0,n_files*len(x.values), 1)[split_index:],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = xr.Dataset(\n",
    "    my_weight_dict,\n",
    "    coords={\n",
    "        \"norm\":np.arange(1,6,1),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.to_netcdf(savepath + \"_train.nc\")\n",
    "ds_test.to_netcdf(savepath + \"_test.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
